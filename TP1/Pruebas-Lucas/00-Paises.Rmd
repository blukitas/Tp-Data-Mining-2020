---
title: "R Notebook"
output: html_notebook
---

```{r}

library("ggplot2")
library("readr")
library("dplyr")
library("highcharter")
library("treemap")
library("modeest")
library("GGally")
library("tidyverse")
library("hrbrthemes")
library("tidyr")
library("VIM")
library("e1071")
library("mice")
library("mongolite")

library("SnowballC")
library("tm")
library("twitteR")
library("syuzhet")

library("tidyverse")
library("lubridate")

library("wordcloud")
library("wordcloud2")
library("RColorBrewer")
```


# Paises 
```{r}

# tweets <- mongo(collection = "tweets_mongo_covid19", db = "DMUBA")
t <- mongo(collection = "tweet_usa", db = "DMUBA")
eeuu <- t$find()
eeuu$pais <- "Estados Unidos"
t <- mongo(collection = "tweet_chile", db = "DMUBA")
chile <- t$find()
chile$pais <- "Chile"
t <- mongo(collection = "tweet_cuba", db = "DMUBA")
cuba <- t$find()
cuba$country <- ""
cuba$pais <- "Cuba"
t <- mongo(collection = "tweet_mx", db = "DMUBA")
mx <- t$find()
mx$pais <- "México"
t <- mongo(collection = "tweet_arg", db = "DMUBA")
arg <- t$find()
arg$pais <- "Argentina"
t <- mongo(collection = "tweet_vz", db = "DMUBA")
vz <- t$find()
vz$country <- ""
vz$pais <- "Venezuela"
```


```{r}
tweets <- rbind(eeuu, chile, cuba, mx, arg, vz)
```

```{r}
tweets$tipo <- ""
tweets[tweets$is_retweet & !tweets$is_quote,]$tipo <- "Solo RT"
tweets[!tweets$is_retweet & tweets$is_quote,]$tipo <- "Solo QT"
tweets[tweets$is_retweet & tweets$is_quote,]$tipo <- "QT y RT"
tweets[!tweets$is_retweet & !tweets$is_quote,]$tipo <- "Original"

grafico_tipos <- data.frame(table(tweets_types$tipo))

# barplot(sort(grafico_tipos$Freq, decreasing=TRUE), legend.text=grafico_tipos$Var1, col=c('red','green','blue','brown'))
ggplot(data=tweets, aes(x=tipo, fill=tipo)) + 
  geom_bar() + facet_wrap(~ pais, nrow=2)

```


```{r}

tweets$verificado <- F
tweets[tweets$tipo == "Solo QT",]$verificado <-  tweets[tweets$tipo == "Solo QT",]$quoted_verified
tweets[tweets$tipo == "Original",]$verificado <-  tweets[tweets$tipo == "Original",]$verified
tweets[tweets$tipo == "Solo RT",]$verificado <-  tweets[tweets$tipo == "Solo RT",]$retweet_verified
tweets[tweets$tipo == "QT y RT",]$verificado <-  tweets[tweets$tipo == "QT y RT",]$retweet_verified

tweets$verificado_grafico <- ""
tweets[tweets$verificado,]$verificado_grafico <- "Verificado"
tweets[!tweets$verificado,]$verificado_grafico <- "No Verificado"

```


```{r}

ggplot(data=tweets, aes(x=verificado, fill=verificado)) + 
  geom_bar() + facet_wrap(~ pais, nrow=2)


# png(filename="tipo_x_tweet.png", width=1000, bg="white")
ggplot(data=tweets, aes(x=verificado_grafico, fill=verificado_grafico)) + 
        scale_fill_brewer(palette="Set2") +
        geom_bar() +
        labs(
          title = "Verificados por tipo de tweet",
          subtitle = "",
          caption = "",
          tag = ""
          ) +
        xlab("") +
        ylab("") +
        theme(plot.title = element_text(hjust = 0.5), 
              axis.title.x = element_text(margin = margin(t = 10, r = 10, b = 10, l = 10)),
              aspect.ratio=18/19) +
        facet_wrap(~ pais, nrow=2)
# dev.off()

```

```{r}
  wordcloud2(data=table(tweets[tweets$pais == 'Argentina',]$retweet_screen_name), size=0.2, color='random-dark')
```


```{r}
for (p in unique(tweets$pais)) {
  print(p)
  print("Top 5 usuarios")
  print(head(sort(table(tweets[tweets$pais == p,]$retweet_screen_name), decreasing=T)))
  print("Top 5 de retweet text")
  print(head(sort(table(tweets[tweets$pais == p,]$retweet_text), decreasing=T), n=1))
  # wordcloud2(data=table(tweets[tweets$pais == p,]$retweet_screen_name), size=0.2, color='random-dark')
}
```




```{r}
limpiar_palabras <- function(df, palabras_filtro) {
  corona_palabras <- c("corona", "coronavirus", "virus", "mas", "cuarentena", "pandemia", "casos")
  # Hay que ver algo, si tiene muchas palabras de coronavirus, podría tratarse de spam, de contenido generado para llamar la atencion.
  
  docs <- df$text
  docs <- gsub("http.*","",docs)
  docs <- gsub("https.*","",docs)
  
  #Quitando los hashtags y usuarios en los tweets_text
  docs <- gsub("#\\w+","",docs)
  docs <- gsub("@\\w+","",docs)
  
  docs <- gsub("[[:punct:]]","",docs)
  docs <- gsub("\\w*[0-9]+\\w*\\s*", "",docs)
  
  docs <- gsub("[[:punct:]]","",docs)
  docs <- gsub("[^[:alnum:][:blank:]?&/\\-]", "", docs)
  docs <- iconv(docs,from="UTF-8",to="ASCII//TRANSLIT")
  
  docs <- Corpus(VectorSource(docs))
  toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
  docs <- tm_map(docs, toSpace, "/")
  docs <- tm_map(docs, toSpace, "@")
  docs <- tm_map(docs, toSpace, "\\|")
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove english common stopwords
  docs <- tm_map(docs, removeWords, stopwords("spanish"))
  # Remove your own stop word
  # specify your stopwords as a character vector
  docs <- tm_map(docs, removeWords, palabras_filtro) 
  docs <- tm_map(docs, removeWords, corona_palabras) 
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  return(docs)
}
```


### Word cloud - Mexico

```{r}

# Me deja sin memoria. Esto haría un wordcloud
tw <- mongo(db="DMUBA", collection="tweet_mx")
tw <- tw$find()

docs <- limpiar_palabras(tw, c("mexico", "méxico"))
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
# dtm <- TermDocumentMatrix(tweets_text.df2$text)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)

set.seed(1234)
# png(filename="nube-mx.png", width=1000, bg="white")
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
# dev.off()

```

```{r}
# Me deja sin memoria. Esto haría un wordcloud
tw <- mongo(db="DMUBA", collection="tweet_cuba")
tw <- tw$find()

docs <- limpiar_palabras(tw, c("cuba", "cubano", "cubana", "cubanos"))
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
# dtm <- TermDocumentMatrix(tweets_text.df2$text)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)

set.seed(1234)
# png(filename="nube-mx.png", width=1000, bg="white")
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
# dev.off()
```




```{r}

# Me deja sin memoria. Esto haría un wordcloud
tw <- mongo(db="DMUBA", collection="tweet_vz")
tw <- tw$find()

docs <- limpiar_palabras(tw, c("venezuela", "venezolano", "venezolana", "venezolanos"))
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
# dtm <- TermDocumentMatrix(tweets_text.df2$text)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)

set.seed(1234)
# png(filename="nube-mx.png", width=1000, bg="white")
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
# dev.off()
```


```{r}

# Me deja sin memoria. Esto haría un wordcloud
tw <- mongo(db="DMUBA", collection="tweet_arg")
tw <- tw$find()

docs <- limpiar_palabras(tw, c("argentina", "argentino", "argentina", "argentinos"))
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
# dtm <- TermDocumentMatrix(tweets_text.df2$text)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)

set.seed(1234)
# png(filename="nube-mx.png", width=1000, bg="white")
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
wordcloud2(data=d[d$freq > 15,], size=0.5, color='random-dark',)
# dev.off()
```

```{r}

# Me deja sin memoria. Esto haría un wordcloud
tw <- mongo(db="DMUBA", collection="tweet_chile")
tw <- tw$find()

docs <- limpiar_palabras(tw, c("chile", "chileno", "chilena", "chilenos"))
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
# dtm <- TermDocumentMatrix(tweets_text.df2$text)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)

set.seed(1234)
# png(filename="nube-mx.png", width=1000, bg="white")
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=100, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
# dev.off()
```

```{r}

# Me deja sin memoria. Esto haría un wordcloud
tw <- mongo(db="DMUBA", collection="tweet_usa")
tw <- tw$find()

docs <- limpiar_palabras(tw, c("eeuu", "estados unidos", "united states", "america"))
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
# dtm <- TermDocumentMatrix(tweets_text.df2$text)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
# head(d, 10)

set.seed(1234)
# png(filename="nube-mx.png", width=1000, bg="white")
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=80, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
# dev.off()
```

